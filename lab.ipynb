{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  挑战1：完成步骤一中的环境配置，使可以进行步骤二中的节点编码。\n",
    "#####  挑战2：代码漏洞检测是一个图级的二分类问题，它在对图节点编码的基础上，进一步得到图级的编码。\n",
    "#####        实现一个Readout层(src/process/model.py)，从节点编码得到代码图的编码表示，从而可以完成步骤三中的模型训练和评估。\n",
    "#####  挑战3：在使用所有训练数据条件下，修改代码的图表示或者模型，使模型的预测准确率达到55%以上(此挑战会根据准确率的提升酌情加分,最高满分)。\n",
    "#####       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一.环境安装\n",
    "# 安装并激活python环境, 已经验证的版本是3.7.2\n",
    "!python --version \n",
    "!conda create -n devign python=3.7.2 #此命令不要重复执行，成功后可注释掉\n",
    "!conda activate devign    \n",
    "# 根据当前机器的情况安装torch、torch-geometric、torch-sparse 和 torch-scatter\n",
    "#   具体安装方法参考 https://pytorch.org/get-started/locally/ \n",
    "# 安装当前试验所依赖的python包\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>target</th>\n",
       "      <th>func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFmpeg</td>\n",
       "      <td>973b1a6b9070e2bf17d17568cbaf4043ce931f51</td>\n",
       "      <td>0</td>\n",
       "      <td>static av_cold int vdadec_init(AVCodecContext ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFmpeg</td>\n",
       "      <td>321b2a9ded0468670b7678b7c098886930ae16b2</td>\n",
       "      <td>0</td>\n",
       "      <td>static int transcode(AVFormatContext **output_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFmpeg</td>\n",
       "      <td>5d5de3eba4c7890c2e8077f5b4ae569671d11cf8</td>\n",
       "      <td>0</td>\n",
       "      <td>static void v4l2_free_buffer(void *opaque, uin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFmpeg</td>\n",
       "      <td>32bf6550cb9cc9f487a6722fe2bfc272a93c1065</td>\n",
       "      <td>0</td>\n",
       "      <td>int ff_get_wav_header(AVFormatContext *s, AVIO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFmpeg</td>\n",
       "      <td>57d77b3963ce1023eaf5ada8cba58b9379405cc8</td>\n",
       "      <td>0</td>\n",
       "      <td>int av_opencl_buffer_write(cl_mem dst_cl_buf, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  project                                 commit_id  target  \\\n",
       "0  FFmpeg  973b1a6b9070e2bf17d17568cbaf4043ce931f51       0   \n",
       "1  FFmpeg  321b2a9ded0468670b7678b7c098886930ae16b2       0   \n",
       "2  FFmpeg  5d5de3eba4c7890c2e8077f5b4ae569671d11cf8       0   \n",
       "3  FFmpeg  32bf6550cb9cc9f487a6722fe2bfc272a93c1065       0   \n",
       "4  FFmpeg  57d77b3963ce1023eaf5ada8cba58b9379405cc8       0   \n",
       "\n",
       "                                                func  \n",
       "0  static av_cold int vdadec_init(AVCodecContext ...  \n",
       "1  static int transcode(AVFormatContext **output_...  \n",
       "2  static void v4l2_free_buffer(void *opaque, uin...  \n",
       "3  int ff_get_wav_header(AVFormatContext *s, AVIO...  \n",
       "4  int av_opencl_buffer_write(cl_mem dst_cl_buf, ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始的代码数据集存放在 data/raw (Paths.raw)中\n",
    "# 每一条数据包含：\n",
    "# project名，commit_id，target（是否为漏洞代码），func（函数代码文本）\n",
    "# 我们探索一下原始数据的构成\n",
    "import pandas as pd\n",
    "dataset = pd.read_json(\"data/raw/dataset.json\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x data/cpg/\n",
      "x data/cpg/36_cpg.pkl\n",
      "x data/cpg/38_cpg.pkl\n",
      "x data/cpg/22_cpg.pkl\n",
      "x data/cpg/2_cpg.pkl\n",
      "x data/cpg/4_cpg.pkl\n",
      "x data/cpg/26_cpg.pkl\n",
      "x data/cpg/13_cpg.pkl\n",
      "x data/cpg/19_cpg.pkl\n",
      "x data/cpg/16_cpg.pkl\n",
      "x data/cpg/20_cpg.pkl\n",
      "x data/cpg/12_cpg.pkl\n",
      "x data/cpg/30_cpg.pkl\n",
      "x data/cpg/8_cpg.pkl\n",
      "x data/cpg/24_cpg.pkl\n",
      "x data/cpg/33_cpg.pkl\n",
      "x data/cpg/37_cpg.pkl\n",
      "x data/cpg/29_cpg.pkl\n",
      "x data/cpg/10_cpg.pkl\n",
      "x data/cpg/28_cpg.pkl\n",
      "x data/cpg/25_cpg.pkl\n",
      "x data/cpg/3_cpg.pkl\n",
      "x data/cpg/32_cpg.pkl\n",
      "x data/cpg/6_cpg.pkl\n",
      "x data/cpg/15_cpg.pkl\n",
      "x data/cpg/11_cpg.pkl\n",
      "x data/cpg/1_cpg.pkl\n",
      "x data/cpg/34_cpg.pkl\n",
      "x data/cpg/7_cpg.pkl\n",
      "x data/cpg/35_cpg.pkl\n",
      "x data/cpg/0_cpg.pkl\n",
      "x data/cpg/21_cpg.pkl\n",
      "x data/cpg/5_cpg.pkl\n",
      "x data/cpg/9_cpg.pkl\n",
      "x data/cpg/17_cpg.pkl\n",
      "x data/cpg/31_cpg.pkl\n",
      "x data/cpg/18_cpg.pkl\n",
      "x data/cpg/14_cpg.pkl\n",
      "x data/cpg/27_cpg.pkl\n",
      "x data/cpg/23_cpg.pkl\n"
     ]
    }
   ],
   "source": [
    "# 使用joern工具将代码数据转化为CPG图\n",
    "# 生成过程比较慢而且需要安装环境，在此省略\n",
    "# 感兴趣的同学可以了解一下joern： https://docs.joern.io/home\n",
    "# 生成的代码图数据存放在data/cpg (Paths.cpg)中，其中每100条数据写入一个文件\n",
    "# 解压代码图数据\n",
    "!tar -xvzf cpg.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 2 to 665\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  98 non-null     int64 \n",
      " 1   func    98 non-null     object\n",
      " 2   Index   98 non-null     int64 \n",
      " 3   cpg     98 non-null     object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 87.9 KB\n",
      "Saving input dataset 0_cpg with size 98.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/39 [00:51<32:21, 51.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\io\\pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2728\u001b[0m, in \u001b[0;36mnew_block\u001b[1;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[0;32m   2727\u001b[0m klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m\n\u001b[0;32m      4\u001b[0m main\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\main.py:110\u001b[0m, in \u001b[0;36membed_task\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pkl_file \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset_files):\n\u001b[0;32m    109\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m pkl_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 110\u001b[0m     cpg_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATHS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkl_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     tokens_dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtokenize(cpg_dataset)  \u001b[38;5;66;03m# 对程序源码文本进行分词，返回分词的结果\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     data\u001b[38;5;241m.\u001b[39mwrite(tokens_dataset, PATHS\u001b[38;5;241m.\u001b[39mtokens, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILES\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\src\\data\\datamanager.py:29\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, pickle_file, ratio)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(path, pickle_file, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 29\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpickle_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     dataset\u001b[38;5;241m.\u001b[39minfo(memory_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\io\\pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\compat\\pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\86150\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py:1210\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     key \u001b[38;5;241m=\u001b[39m read(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 二.图节点代码文本编码\n",
    "# 训练用于编码节点中文本的word2vec模型，并对节点的文本进行编码\n",
    "import main\n",
    "main.setup()\n",
    "main.embed_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 481,401 trainable parameters\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 2 to 665\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   98 non-null     object\n",
      " 1   target  98 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 6879 to 7686\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 7688 to 8327\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 8330 to 9005\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   98 non-null     object\n",
      " 1   target  98 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 105 entries, 9010 to 9614\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   105 non-null    object\n",
      " 1   target  105 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97 entries, 9649 to 10449\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   97 non-null     object\n",
      " 1   target  97 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.8 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 10452 to 11029\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 11031 to 11665\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 97 entries, 11677 to 12421\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   97 non-null     object\n",
      " 1   target  97 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.8 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 12429 to 13199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 13205 to 13712\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 668 to 1372\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 13715 to 14355\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 14359 to 15157\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 15174 to 15908\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 15920 to 16972\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 16973 to 17585\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   99 non-null     object\n",
      " 1   target  99 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 17597 to 18330\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 18334 to 19124\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   target  100 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.0 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 105 entries, 19146 to 19836\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   105 non-null    object\n",
      " 1   target  105 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 103 entries, 19842 to 20565\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   103 non-null    object\n",
      " 1   target  103 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 20578 to 21227\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   98 non-null     object\n",
      " 1   target  98 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 1373 to 1962\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   98 non-null     object\n",
      " 1   target  98 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.9 KB\n",
      "Splitting Dataset\n",
      "train with cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 三.模型训练和验证\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\main.py:186\u001b[0m, in \u001b[0;36mprocess_task\u001b[1;34m(stopping, test_only)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stopping:\n\u001b[0;32m    180\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m    181\u001b[0m         model,\n\u001b[0;32m    182\u001b[0m         patience\u001b[38;5;241m=\u001b[39mcontext\u001b[38;5;241m.\u001b[39mpatience,\n\u001b[0;32m    183\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mPROCESS_PARAMS\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    184\u001b[0m         delta\u001b[38;5;241m=\u001b[39mPROCESS_PARAMS\u001b[38;5;241m.\u001b[39mdelta,\n\u001b[0;32m    185\u001b[0m     )\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     model\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\src\\process\\modeling.py:17\u001b[0m, in \u001b[0;36mTrain.__call__\u001b[1;34m(self, train_loader_step, val_loader_step, early_stopping)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 17\u001b[0m     train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loader_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory(train_stats, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\src\\process\\loader_step.py:17\u001b[0m, in \u001b[0;36mLoaderStep.__call__\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader)):\n\u001b[0;32m     16\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 17\u001b[0m     stat: stats\u001b[38;5;241m.\u001b[39mStat \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats(stat)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\src\\process\\step.py:20\u001b[0m, in \u001b[0;36mStep.__call__\u001b[1;34m(self, i, x, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, x, y):\n\u001b[0;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m---> 20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     acc \u001b[38;5;241m=\u001b[39m softmax_accuracy(out, y\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# calculates the gradient\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\86150\\Desktop\\图神经网络\\devign_lab-main\\src\\process\\devign.py:25\u001b[0m, in \u001b[0;36mDevign.__init__.<locals>.<lambda>\u001b[1;34m(o, t)\u001b[0m\n\u001b[0;32m     22\u001b[0m log\u001b[38;5;241m.\u001b[39mlog_info(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevign\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; WD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; LL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m _model \u001b[38;5;241m=\u001b[39m Net(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel, max_nodes\u001b[38;5;241m=\u001b[39mmax_nodes, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39m_model,\n\u001b[1;32m---> 25\u001b[0m                  loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m o, t: \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m F\u001b[38;5;241m.\u001b[39ml1_loss(o, t) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll,\n\u001b[0;32m     26\u001b[0m                  optimizer\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwd),\n\u001b[0;32m     27\u001b[0m                  )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_parameters()\n",
      "File \u001b[1;32mc:\\users\\86150\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\nn\\functional.py:3172\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3169\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3170\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 三.模型训练和验证\n",
    "import main\n",
    "main.process_task(True, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
